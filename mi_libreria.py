# -*- coding: utf-8 -*-
"""Mi Libreria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O6QdREqcHwfQYCR6zMDxq1K2qTDaxgp9
"""

class ResumenGrafico:
    def __init__(self, datos):
        self.datos = np.array(datos)

    def generacion_histograma(self, h):
        val_min = min(self.datos)
        val_max = max(self.datos)
        bins = np.arange(val_min, val_max, h)
        if val_max > bins[-1]:
            bins = np.append(bins, bins[-1] + h)

        m = len(bins)
        histo = [0] * (m - 1)  # El histograma tiene m-1 bins
        for valor in self.datos:
            for i in range(len(bins) - 1):
                if valor == bins[0]:
                    histo[0] += 1
                    break
                elif bins[i] < valor <= bins[i + 1]:
                    histo[i] += 1
                    break
        for i in range(len(histo)):
            histo[i] /= (len(self.datos) * h)

        return bins, histo

    def evalua_histograma(self, h, x):
        bins, histo = self.generacion_histograma(h)

        res = [0] * len(x)
        for j in range(len(x)):
            if x[j] == min(self.datos):
                res[j] = histo[0]
            else:
                for i in range(len(bins) - 1):
                    if bins[i] < x[j] <= bins[i + 1]:
                        res[j] = histo[i]
                        break
        return res

    def kernel_gaussiano(self,x):
      valor_kernel_gaussiano = (1/(np.sqrt(2*pi)))* exp(-0.5*(x**2))
      return valor_kernel_gaussiano

    def kernel_uniforme(self,x):
      if -0.5 < x <= 0.5:
        valor_kernel_uniforme = 1
      else:
        valor_kernel_uniforme =  0
      return valor_kernel_uniforme

    def kernel_cuadratico(self,x):
      if -1 <= x <= 1:
        valor_kernel_cuadratico = 0.75 * (1-(x**2))
      else:
        valor_kernel_cuadratico = 0
      return valor_kernel_cuadratico

    def kernel_triangular(self,x):
      if -1 <= x <= 0:
        valor_kernel_triangular = 1+x
      elif 0 <= x <= 1:
        valor_kernel_triangular = 1-x
      else:
        valor_kernel_triangular = 0

      return valor_kernel_triangular

    def densidad_nucleo(self,h,kernel,x):
      density = np.zeros(len(x))
      data = self.datos
      for i in range(len(x)):
            contador = 0
            for j in range(len(data)):
                dato = (data[j]-x[i]) / h

                if kernel == "gaussiano":
                  contador += self.kernel_gaussiano(dato)
                elif kernel == "uniforme":
                  contador += self.kernel_uniforme(dato)
                elif kernel == "cuadratico":
                  contador += self.kernel_cuadratico(dato)
                elif kernel == "triangular":
                  contador += self.kernel_triangular(dato)

            density[i] = contador /(len(data) * h)
      return density

class GeneradoraDeDatos:
    def __init__(self, tamaño):
          self.tamaño = tamaño

    def generar_datos_dist_norm(self,media,desvio):
      tamaño = self.tamaño
      datos_normales = norm.rvs(media,desvio,tamaño)
      return datos_normales

    def pdf_norm(self,x,media,desvio):
      curva = norm.pdf(x,media,desvio)
      return curva

    def generar_datos_bs(self):
        u = np.random.uniform(size=(self.tamaño,))
        y = u.copy()
        ind = np.where(u > 0.5)[0]
        y[ind] = np.random.normal(0, 1, size=len(ind))
        for j in range(5):
          ind = np.where((u > j * 0.1) & (u <= (j+1) * 0.1))[0]
          y[ind] = np.random.normal(j/2 - 1, 1/10, size=len(ind))

        return y
    def curva_bs(self,x):
      dato = 0.5* norm.pdf(x,0,1)
      sumatoria = 0
      for i in range(5):
        sumatoria = sumatoria + norm.pdf(x,(i/2)-1,0.1)
      densidad = dato + (0.1* sumatoria)
      return densidad




class Regresion:
  def __init__(self, x,y):
        self.x = x
        self.y = y

  def coef_correlacion(self):
    for i in range(self.x.shape[1]):
      print('Coeficiencite de correlacion:', np.corrcoef(self.x[:,i],self.y)[0,1])

  def estimaciones(self):
    betas = self.resultado.params
    valores_ajustados = self.resultado.fittedvalues
    p_valores = self.resultado.pvalues
    errores = self.resultado.bse
    lista = {"parametros": betas, "bse": errores,"p-valores":p_valores,"valores_ajustados":valores_ajustados}
    return lista

  def supuestos(self):
    residuos = self.resultado.resid
    residuos_z = (residuos-np.mean(residuos))/np.std(residuos)
    valores_ajustados = self.resultado.fittedvalues
    plt.scatter(valores_ajustados,residuos)
    plt.plot(valores_ajustados, [0]*len(valores_ajustados), color="red");
    sm.qqplot(residuos_z,line='45')
    return residuos

  def prediccion(self,x_new):
    predicciones = self.resultado.predict(x_new)
    return predicciones

class RegresionLineal(Regresion):
  def __init__(self, x, y):
        super().__init__(x, y)

  def modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.OLS(self.y, X)
    self.resultado = modelo.fit()

  def grafica(self):
    for i in range(self.x.shape[1]):
      media_x = np.mean(self.x[:,i])
      media_y = np.mean(self.y)
      b1 = (sum((self.x[:,i]-media_x)*(self.y-media_y)))/(sum((self.x[:,i]-media_x)**2))
      b0 = media_y - b1 * media_x
      recta = b0 + b1 * self.x[:,i]
      plt.figure()
      plt.plot(self.x[:,i],recta, label = 'x[i]')
      plt.scatter(self.x[:,i],self.y, color= 'red')
      plt.xlabel('Eje de las x')
      plt.ylabel('Eje de las y')

  def intervalos(self,x_new,alfa):
    prediccion = self.resultado.get_prediction(x_new)
    int_pred = prediccion.conf_int(obs=True,alpha=alfa)
    int_conf =prediccion.conf_int(alpha=alfa)
    lista = {"Intervalo de pred": int_pred, "Intervalo de confi": int_conf}
    return lista

  def r_cuadrado(self):
    r_cuadrado = self.resultado.rsquared
    r_ajustado = self.resultado.rsquared_adj
    return r_cuadrado, r_ajustado

  pass

class RegresionLogistica(Regresion):
  def __init__(self, x, y):
        super().__init__(x, y)

  def modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.Logit(self.y, X)
    self.resultado = modelo.fit()

  def matriz_conf(self,x_train,y_train,x_test,y_test,umbral):
    self.y_test = y_test
    self.x_test = x_test
    X = sm.add_constant(x_train)
    modelo_train = sm.Logit(y_train,X)
    resultado_tr = modelo_train.fit()
    X_test = sm.add_constant(x_test)
    self.probabilidades = resultado_tr.predict(X_test)
    self.y_pred = 1*(self.probabilidades>=umbral)
    a = sum((self.y_pred==1) & (y_test==1))
    b = sum((self.y_pred==1) & (y_test==0))
    c = sum((self.y_pred==0) & (y_test==1))
    d = sum((self.y_pred==0) & (y_test==0))
    error = (b + c)/len(self.y_test)
    print('El error de mala clasificación es:', error)
    lista = {"Verdaderos positivos": a, "Falsos positivos": b,"Verdaderos negativos":d,"Falsos negativos":c}
    return lista

  def sens_esp(self):
    grilla = np.linspace(0,1,100)
    sensi = []
    espe = []
    for i in grilla:
      y_pred1= 1*(self.probabilidades>=i)
      np.array(sensi.append(sum((y_pred1==1) & (self.y_test==1))/sum(self.y_test)))
      np.array(espe.append(sum((y_pred1==0) & (self.y_test==0))/(len(self.x_test)-sum(self.y_test))))

    promedios = np.array(sensi)+(np.array(espe)-1)
    punto_corte = float(grilla[np.where(max(promedios)==promedios)[0][0]])
    sensibilidad = float(sensi[np.where(max(promedios)==promedios)[0][0]])
    especificidad = float(espe[np.where(max(promedios)==promedios)[0][0]])
    lista = {"punto de corte": punto_corte, "sensibilidad": sensibilidad,"especificidad":especificidad}
    plt.plot(1-np.array(espe),sensi);
    plt.xlabel('1-especificidad')
    plt.ylabel('sensibilidad')
    return lista

class cualis():

  def __init__(self, obtenidos, probabilidades, alfa):
    self.obtenidos = obtenidos
    self.probabilidades = probabilidades
    self.alfa = alfa
    self.cantidad = sum(self.obtenidos)

  def esperados(self):
    self.esperados = self.cantidad * np.array(self.probabilidades)
    return self.esperados

  def chi_2(self):
    self.chi_2 = sum((self.obtenidos-self.esperados)**2/self.esperados)
    return self.chi_2

  def punto_chi_2(self):
    from scipy.stats import chi2
    self.punto = chi2.ppf(1 - self.alfa, len(self.probabilidades)-1)
    return self.punto

  def p_valor(self):
    from scipy.stats import chi2
    self.p_valor = 1 - chi2.cdf(self.chi_2,len(self.probabilidades)-1)
    return self.p_valor

  pass